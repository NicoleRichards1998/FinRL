{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoleRichards1998/FinRL/blob/master/Optimisation_DayTrading_FinRL_JSE_Singe_Stock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyjlFHYYuJi0"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from numpy import random as rd\n",
        "\n",
        "class NoIndicatorsStockTradingEnv(gym.Env):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        initial_account=1e6,\n",
        "        gamma=0.99,\n",
        "        turbulence_thresh=50000,\n",
        "        min_stock_rate=0.1,\n",
        "        max_stock=1e2,\n",
        "        initial_capital=1e6,\n",
        "        buy_cost_pct=1e-3,\n",
        "        sell_cost_pct=1e-3,\n",
        "        reward_scaling=2 ** -11,\n",
        "        initial_stocks=None,\n",
        "    ):\n",
        "        price_ary = config[\"price_array\"]\n",
        "        #tech_ary = config[\"tech_array\"]\n",
        "        turbulence_ary = config[\"turbulence_array\"]\n",
        "        if_train = config[\"if_train\"]\n",
        "        self.price_ary = price_ary.astype(np.float32)\n",
        "        #self.tech_ary = tech_ary.astype(np.float32)\n",
        "        self.turbulence_ary = turbulence_ary\n",
        "\n",
        "        #self.tech_ary = self.tech_ary * 2 ** -7\n",
        "        self.turbulence_bool = (turbulence_ary > turbulence_thresh).astype(np.float32)\n",
        "        self.turbulence_ary = (\n",
        "            self.sigmoid_sign(turbulence_ary, turbulence_thresh) * 2 ** -5\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        stock_dim = self.price_ary.shape[1]\n",
        "        self.gamma = gamma\n",
        "        self.max_stock = max_stock\n",
        "        self.min_stock_rate = min_stock_rate\n",
        "        self.buy_cost_pct = buy_cost_pct\n",
        "        self.sell_cost_pct = sell_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.initial_capital = initial_capital\n",
        "        self.initial_stocks = (\n",
        "            np.zeros(stock_dim, dtype=np.float32)\n",
        "            if initial_stocks is None\n",
        "            else initial_stocks\n",
        "        )\n",
        "\n",
        "        # reset()\n",
        "        self.day = None\n",
        "        self.amount = None\n",
        "        self.stocks = None\n",
        "        self.total_asset = None\n",
        "        self.gamma_reward = None\n",
        "        self.initial_total_asset = None\n",
        "        \n",
        "        self.sell_index = False\n",
        "\n",
        "        # environment information\n",
        "        self.env_name = \"StockEnv\"\n",
        "        # self.state_dim = 1 + 2 + 2 * stock_dim + self.tech_ary.shape[1]\n",
        "        # # amount + (turbulence, turbulence_bool) + (price, stock) * stock_dim + tech_dim\n",
        "        self.state_dim = 1 + 2 + 3 * stock_dim\n",
        "        # amount + (turbulence, turbulence_bool) + (price, stock) * stock_dim + tech_dim\n",
        "        self.stocks_cd = None\n",
        "        self.action_dim = stock_dim\n",
        "        self.max_step = self.price_ary.shape[0] - 1\n",
        "        self.if_train = if_train\n",
        "        self.if_discrete = False\n",
        "        self.target_return = 10.0\n",
        "        self.episode_return = 0.0\n",
        "\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=-3000, high=3000, shape=(self.state_dim,), dtype=np.float32\n",
        "        )\n",
        "        self.action_space = gym.spaces.Box(\n",
        "            low=-1, high=1, shape=(self.action_dim,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self):\n",
        "        self.day = 0\n",
        "        price = self.price_ary[self.day]\n",
        "\n",
        "        if self.if_train:\n",
        "            self.stocks = (\n",
        "                self.initial_stocks + rd.randint(0, 64, size=self.initial_stocks.shape)\n",
        "            ).astype(np.float32)\n",
        "            self.stocks_cool_down = np.zeros_like(self.stocks)\n",
        "            self.amount = (\n",
        "                self.initial_capital * rd.uniform(0.95, 1.05)\n",
        "                - (self.stocks * price).sum()\n",
        "            )\n",
        "        else:\n",
        "            self.stocks = self.initial_stocks.astype(np.float32)\n",
        "            self.stocks_cool_down = np.zeros_like(self.stocks)\n",
        "            self.amount = self.initial_capital\n",
        "\n",
        "        self.total_asset = self.amount + (self.stocks * price).sum()\n",
        "        self.initial_total_asset = self.total_asset\n",
        "        self.gamma_reward = 0.0\n",
        "        return self.get_state(price)  # state\n",
        "\n",
        "    def step(self, actions):\n",
        "        actions = (actions * self.max_stock).astype(int)\n",
        "\n",
        "        self.day += 1\n",
        "        price = self.price_ary[self.day]\n",
        "        self.stocks_cool_down += 1\n",
        "        sell_index = self.sell_index\n",
        "\n",
        "        if self.turbulence_bool[self.day] == 0:\n",
        "            min_action = int(self.max_stock * self.min_stock_rate)  # stock_cd\n",
        "            for index in np.where(actions < -min_action)[0]:  # sell_index:\n",
        "                if price[index] > 0:  # Sell only if current asset is > 0\n",
        "                    sell_num_shares = min(self.stocks[index], -actions[index])\n",
        "                    self.stocks[index] -= sell_num_shares\n",
        "                    self.amount += (\n",
        "                        price[index] * sell_num_shares * (1 - self.sell_cost_pct)\n",
        "                    )\n",
        "                    self.stocks_cool_down[index] = 0\n",
        "                    sell_index = True\n",
        "            for index in np.where(actions > min_action)[0]:  # buy_index:\n",
        "                if (\n",
        "                    price[index] > 0\n",
        "                ):  # Buy only if the price is > 0 (no missing data in this particular date)\n",
        "                    buy_num_shares = min(self.amount // price[index], actions[index])\n",
        "                    self.stocks[index] += buy_num_shares\n",
        "                    self.amount -= (\n",
        "                        price[index] * buy_num_shares * (1 + self.buy_cost_pct)\n",
        "                    )\n",
        "                    self.stocks_cool_down[index] = 0\n",
        "\n",
        "        else:  # sell all when turbulence\n",
        "            self.amount += (self.stocks * price).sum() * (1 - self.sell_cost_pct)\n",
        "            self.stocks[:] = 0\n",
        "            self.stocks_cool_down[:] = 0\n",
        "\n",
        "        state = self.get_state(price)\n",
        "        total_asset = self.amount + (self.stocks * price).sum()\n",
        "        real_reward = (total_asset - self.total_asset) * self.reward_scaling\n",
        "        self.total_asset = total_asset\n",
        "\n",
        "        # for my reward function\n",
        "        \n",
        "        #if sell_index == True:\n",
        "        #  reward = real_reward\n",
        "        #  sell_index = False\n",
        "        #else:\n",
        "        #  reward = int(0)\n",
        "        #print('reward', reward)\n",
        "\n",
        "        # for reward at end\n",
        "\n",
        "        #reward = int(0)\n",
        "\n",
        "        # for OG reward function\n",
        "\n",
        "        reward = (total_asset - self.total_asset) * self.reward_scaling\n",
        "\n",
        "        # the rest\n",
        "\n",
        "        self.gamma_reward = self.gamma_reward * self.gamma + real_reward\n",
        "        done = self.day == self.max_step\n",
        "        if done:\n",
        "            reward = self.gamma_reward\n",
        "            self.episode_return = total_asset / self.initial_total_asset\n",
        "\n",
        "        return state, reward, done, dict()\n",
        "\n",
        "    def get_state(self, price):\n",
        "        amount = np.array(self.amount * (2 ** -12), dtype=np.float32)\n",
        "        scale = np.array(2 ** -6, dtype=np.float32)\n",
        "        return np.hstack(\n",
        "            (\n",
        "                amount,\n",
        "                self.turbulence_ary[self.day],\n",
        "                self.turbulence_bool[self.day],\n",
        "                price * scale,\n",
        "                self.stocks * scale,\n",
        "                self.stocks_cool_down,\n",
        "            )\n",
        "        )  # state.astype(np.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid_sign(ary, thresh):\n",
        "        def sigmoid(x):\n",
        "            return 1 / (1 + np.exp(-x * np.e)) - 0.5\n",
        "\n",
        "        return sigmoid(ary / thresh) * thresh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "UMJ307gTeoNQ"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "from numpy import random as rd\n",
        "\n",
        "class RandomEnv(gym.Env):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        initial_account=1e6,\n",
        "        gamma=0.99,\n",
        "        turbulence_thresh=50000,\n",
        "        min_stock_rate=0.1,\n",
        "        max_stock=1e2,\n",
        "        initial_capital=1e6,\n",
        "        buy_cost_pct=1e-3,\n",
        "        sell_cost_pct=1e-3,\n",
        "        reward_scaling=2 ** -11,\n",
        "        initial_stocks=None,\n",
        "    ):\n",
        "        price_ary = config[\"price_array\"]\n",
        "        #tech_ary = config[\"tech_array\"]\n",
        "        turbulence_ary = config[\"turbulence_array\"]\n",
        "        if_train = config[\"if_train\"]\n",
        "        self.price_ary = price_ary.astype(np.float32)\n",
        "        #self.tech_ary = tech_ary.astype(np.float32)\n",
        "        self.turbulence_ary = turbulence_ary\n",
        "\n",
        "        #self.tech_ary = self.tech_ary * 2 ** -7\n",
        "        self.turbulence_bool = (turbulence_ary > turbulence_thresh).astype(np.float32)\n",
        "        self.turbulence_ary = (\n",
        "            self.sigmoid_sign(turbulence_ary, turbulence_thresh) * 2 ** -5\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        stock_dim = self.price_ary.shape[1]\n",
        "        self.gamma = gamma\n",
        "        self.max_stock = max_stock\n",
        "        self.min_stock_rate = min_stock_rate\n",
        "        self.buy_cost_pct = buy_cost_pct\n",
        "        self.sell_cost_pct = sell_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.initial_capital = initial_capital\n",
        "        self.initial_stocks = (\n",
        "            np.zeros(stock_dim, dtype=np.float32)\n",
        "            if initial_stocks is None\n",
        "            else initial_stocks\n",
        "        )\n",
        "\n",
        "        # reset()\n",
        "        self.day = None\n",
        "        self.amount = None\n",
        "        self.stocks = None\n",
        "        self.total_asset = None\n",
        "        self.gamma_reward = None\n",
        "        self.initial_total_asset = None\n",
        "        \n",
        "        self.sell_index = False\n",
        "\n",
        "        # environment information\n",
        "        self.env_name = \"StockEnv\"\n",
        "        # self.state_dim = 1 + 2 + 2 * stock_dim + self.tech_ary.shape[1]\n",
        "        # # amount + (turbulence, turbulence_bool) + (price, stock) * stock_dim + tech_dim\n",
        "        self.state_dim = 1 + 2 + 3 * stock_dim\n",
        "        # amount + (turbulence, turbulence_bool) + (price, stock) * stock_dim + tech_dim\n",
        "        self.stocks_cd = None\n",
        "        self.action_dim = stock_dim\n",
        "        self.max_step = self.price_ary.shape[0] - 1\n",
        "        self.if_train = if_train\n",
        "        self.if_discrete = False\n",
        "        self.target_return = 10.0\n",
        "        self.episode_return = 0.0\n",
        "\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=-3000, high=3000, shape=(self.state_dim,), dtype=np.float32\n",
        "        )\n",
        "        self.action_space = gym.spaces.Box(\n",
        "            low=-1, high=1, shape=(self.action_dim,), dtype=np.float32\n",
        "        )\n",
        "\n",
        "    def reset(self):\n",
        "        self.day = 0\n",
        "        price = self.price_ary[self.day]\n",
        "\n",
        "        if self.if_train:\n",
        "            self.stocks = (\n",
        "                self.initial_stocks + rd.randint(0, 64, size=self.initial_stocks.shape)\n",
        "            ).astype(np.float32)\n",
        "            self.stocks_cool_down = np.zeros_like(self.stocks)\n",
        "            self.amount = (\n",
        "                self.initial_capital * rd.uniform(0.95, 1.05)\n",
        "                - (self.stocks * price).sum()\n",
        "            )\n",
        "        else:\n",
        "            self.stocks = self.initial_stocks.astype(np.float32)\n",
        "            self.stocks_cool_down = np.zeros_like(self.stocks)\n",
        "            self.amount = self.initial_capital\n",
        "\n",
        "        self.total_asset = self.amount + (self.stocks * price).sum()\n",
        "        self.initial_total_asset = self.total_asset\n",
        "        self.gamma_reward = 0.0\n",
        "        return self.get_state(price)  # state\n",
        "\n",
        "    def step(self, actions):\n",
        "        #actions = np.array(rd.uniform(-1, 1), dtype=np.float32)\n",
        "        #actions = (actions * self.max_stock).astype(int)\n",
        "\n",
        "        actions = np.array([rd.uniform(-1, 1)])\n",
        "        actions = (actions * self.max_stock)\n",
        "\n",
        "        self.day += 1\n",
        "        price = self.price_ary[self.day]\n",
        "        self.stocks_cool_down += 1\n",
        "        sell_index = self.sell_index\n",
        "\n",
        "        if self.turbulence_bool[self.day] == 0:\n",
        "            min_action = int(self.max_stock * self.min_stock_rate)  # stock_cd\n",
        "            for index in np.where(actions < -min_action)[0]:  # sell_index:\n",
        "                if price[index] > 0:  # Sell only if current asset is > 0\n",
        "                    sell_num_shares = min(self.stocks[index], -actions[index])\n",
        "                    self.stocks[index] -= sell_num_shares\n",
        "                    self.amount += (\n",
        "                        price[index] * sell_num_shares * (1 - self.sell_cost_pct)\n",
        "                    )\n",
        "                    self.stocks_cool_down[index] = 0\n",
        "                    sell_index = True\n",
        "            for index in np.where(actions > min_action)[0]:  # buy_index:\n",
        "                if (\n",
        "                    price[index] > 0\n",
        "                ):  # Buy only if the price is > 0 (no missing data in this particular date)\n",
        "                    buy_num_shares = min(self.amount // price[index], actions[index])\n",
        "                    self.stocks[index] += buy_num_shares\n",
        "                    self.amount -= (\n",
        "                        price[index] * buy_num_shares * (1 + self.buy_cost_pct)\n",
        "                    )\n",
        "                    self.stocks_cool_down[index] = 0\n",
        "\n",
        "        else:  # sell all when turbulence\n",
        "            self.amount += (self.stocks * price).sum() * (1 - self.sell_cost_pct)\n",
        "            self.stocks[:] = 0\n",
        "            self.stocks_cool_down[:] = 0\n",
        "\n",
        "        state = self.get_state(price)\n",
        "        total_asset = self.amount + (self.stocks * price).sum()\n",
        "        real_reward = (total_asset - self.total_asset) * self.reward_scaling\n",
        "        self.total_asset = total_asset\n",
        "\n",
        "        # for my reward function\n",
        "        \n",
        "        #if sell_index == True:\n",
        "        #  reward = real_reward\n",
        "        #  sell_index = False\n",
        "        #else:\n",
        "        #  reward = int(0)\n",
        "        #print('reward', reward)\n",
        "\n",
        "        # for reward at end\n",
        "\n",
        "        #reward = int(0)\n",
        "\n",
        "        # for OG reward function\n",
        "\n",
        "        reward = (total_asset - self.total_asset) * self.reward_scaling\n",
        "\n",
        "        # the rest\n",
        "\n",
        "        self.gamma_reward = self.gamma_reward * self.gamma + real_reward\n",
        "        done = self.day == self.max_step\n",
        "        if done:\n",
        "            reward = self.gamma_reward\n",
        "            self.episode_return = total_asset / self.initial_total_asset\n",
        "\n",
        "        return state, reward, done, dict()\n",
        "\n",
        "    def get_state(self, price):\n",
        "        amount = np.array(self.amount * (2 ** -12), dtype=np.float32)\n",
        "        scale = np.array(2 ** -6, dtype=np.float32)\n",
        "        return np.hstack(\n",
        "            (\n",
        "                amount,\n",
        "                self.turbulence_ary[self.day],\n",
        "                self.turbulence_bool[self.day],\n",
        "                price * scale,\n",
        "                self.stocks * scale,\n",
        "                self.stocks_cool_down,\n",
        "            )\n",
        "        )  # state.astype(np.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def sigmoid_sign(ary, thresh):\n",
        "        def sigmoid(x):\n",
        "            return 1 / (1 + np.exp(-x * np.e)) - 0.5\n",
        "\n",
        "        return sigmoid(ary / thresh) * thresh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import random as rd\n",
        "actions = np.array([rd.uniform(-1, 1)])\n",
        "actions = (actions * 100)\n",
        "actions[0]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVo775bsi46N",
        "outputId": "84be2d9a-763f-4659-de41-00fae289bbfa"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-4.915787548913642"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "actions = rd.uniform(-1, 1)\n",
        "actions = [actions * 0.1]\n",
        "actions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7OILTLTdPQh",
        "outputId": "39389b1c-57de-483d-d4c2-919c426095fc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03540906386662768"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3mbRu3s1YlD"
      },
      "source": [
        "# Part 1: Install FinRL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bsoRILKIEqgn",
        "outputId": "063770d4-12ba-468e-e04d-bd014ecb126a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/NicoleRichards1998/FinRL.git\n",
            "  Cloning https://github.com/NicoleRichards1998/FinRL.git to /tmp/pip-req-build-bgbzvr7w\n",
            "  Running command git clone -q https://github.com/NicoleRichards1998/FinRL.git /tmp/pip-req-build-bgbzvr7w\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-p8v8mza0/pyfolio_248e61405553440d8e10adc538456783\n",
            "  Running command git clone -q https://github.com/quantopian/pyfolio.git /tmp/pip-install-p8v8mza0/pyfolio_248e61405553440d8e10adc538456783\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-p8v8mza0/elegantrl_33e5d82851c74190b34891d1c6bfbdda\n",
            "  Running command git clone -q https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-p8v8mza0/elegantrl_33e5d82851c74190b34891d1c6bfbdda\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.3.5)\n",
            "Collecting stockstats>=0.4.0\n",
            "  Downloading stockstats-0.4.1-py2.py3-none-any.whl (19 kB)\n",
            "Collecting yfinance\n",
            "  Downloading yfinance-0.1.72-py2.py3-none-any.whl (27 kB)\n",
            "Collecting elegantrl\n",
            "  Downloading elegantrl-0.3.3-py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (1.0.2)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.17.3)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-1.5.0-py3-none-any.whl (177 kB)\n",
            "\u001b[K     |████████████████████████████████| 177 kB 70.6 MB/s \n",
            "\u001b[?25hCollecting ray[default]\n",
            "  Downloading ray-1.13.0-cp37-cp37m-manylinux2014_x86_64.whl (54.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.5 MB 251 kB/s \n",
            "\u001b[?25hCollecting lz4\n",
            "  Downloading lz4-4.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 59.3 MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 75.8 MB/s \n",
            "\u001b[?25hCollecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Collecting exchange_calendars\n",
            "  Downloading exchange_calendars-3.6.3.tar.gz (152 kB)\n",
            "\u001b[K     |████████████████████████████████| 152 kB 52.1 MB/s \n",
            "\u001b[?25hCollecting alpaca_trade_api\n",
            "  Downloading alpaca_trade_api-2.3.0-py3-none-any.whl (33 kB)\n",
            "Collecting ccxt==1.66.32\n",
            "  Downloading ccxt-1.66.32-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 52.6 MB/s \n",
            "\u001b[?25hCollecting jqdatasdk\n",
            "  Downloading jqdatasdk-1.8.10-py3-none-any.whl (153 kB)\n",
            "\u001b[K     |████████████████████████████████| 153 kB 75.6 MB/s \n",
            "\u001b[?25hCollecting wrds\n",
            "  Downloading wrds-3.1.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (3.6.4)\n",
            "Collecting setuptools==59.5.0\n",
            "  Downloading setuptools-59.5.0-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 59.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.33.6 in /usr/local/lib/python3.7/dist-packages (from finrl==0.3.5) (0.37.1)\n",
            "Collecting pre-commit\n",
            "  Downloading pre_commit-2.19.0-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 72.6 MB/s \n",
            "\u001b[?25hCollecting pybullet\n",
            "  Downloading pybullet-3.2.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (91.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 91.7 MB 35 kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (1.11.0+cu113)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl->finrl==0.3.5) (4.1.2.30)\n",
            "Collecting box2d-py\n",
            "  Downloading box2d_py-2.3.8-cp37-cp37m-manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 68.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.5.0)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2022.1)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.4.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.11.2)\n",
            "Collecting empyrical>=0.5.0\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.6.1\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 56.3 MB/s \n",
            "\u001b[?25hCollecting aiohttp>=3.8\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 52.8 MB/s \n",
            "\u001b[?25hCollecting yarl==1.7.2\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 63.7 MB/s \n",
            "\u001b[?25hCollecting aiodns>=1.1.1\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.7/dist-packages (from ccxt==1.66.32->finrl==0.3.5) (2022.6.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (4.1.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl==1.7.2->ccxt==1.66.32->finrl==0.3.5) (2.10)\n",
            "Collecting multidict>=4.0\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 858 kB/s \n",
            "\u001b[?25hCollecting pycares>=4.0.0\n",
            "  Downloading pycares-4.2.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (291 kB)\n",
            "\u001b[K     |████████████████████████████████| 291 kB 75.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.8->ccxt==1.66.32->finrl==0.3.5) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 75.7 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.6.1->ccxt==1.66.32->finrl==0.3.5) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt==1.66.32->finrl==0.3.5) (2.21)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.7/dist-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.5) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17->finrl==0.3.5) (1.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.1.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (1.4.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->finrl==0.3.5) (0.11.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.2.6)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17->finrl==0.3.5) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->ccxt==1.66.32->finrl==0.3.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.18.4->ccxt==1.66.32->finrl==0.3.5) (1.24.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (3.1.0)\n",
            "Collecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting websockets<11,>=9.0\n",
            "  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 66.6 MB/s \n",
            "\u001b[?25hCollecting msgpack==1.0.3\n",
            "  Downloading msgpack-1.0.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[K     |████████████████████████████████| 299 kB 77.9 MB/s \n",
            "\u001b[?25hCollecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.3.3-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 69.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from deprecation==2.1.0->alpaca_trade_api->finrl==0.3.5) (21.3)\n",
            "Collecting pyluach\n",
            "  Downloading pyluach-2.0.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.5) (0.11.2)\n",
            "Requirement already satisfied: korean_lunar_calendar in /usr/local/lib/python3.7/dist-packages (from exchange_calendars->finrl==0.3.5) (0.2.1)\n",
            "Collecting pymysql>=0.7.6\n",
            "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n",
            "\u001b[?25hCollecting thriftpy2>=0.3.9\n",
            "  Downloading thriftpy2-0.4.14.tar.gz (361 kB)\n",
            "\u001b[K     |████████████████████████████████| 361 kB 74.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: SQLAlchemy>=1.2.8 in /usr/local/lib/python3.7/dist-packages (from jqdatasdk->finrl==0.3.5) (1.4.37)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.5) (1.1.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.5) (4.11.4)\n",
            "Collecting ply<4.0,>=3.4\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->SQLAlchemy>=1.2.8->jqdatasdk->finrl==0.3.5) (3.8.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.0)\n",
            "Collecting virtualenv>=20.0.8\n",
            "  Downloading virtualenv-20.15.1-py2.py3-none-any.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 55.0 MB/s \n",
            "\u001b[?25hCollecting toml\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting cfgv>=2.0.0\n",
            "  Downloading cfgv-3.3.1-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting nodeenv>=0.11.1\n",
            "  Downloading nodeenv-1.7.0-py2.py3-none-any.whl (21 kB)\n",
            "Collecting identify>=1.0.0\n",
            "  Downloading identify-2.5.1-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 10.4 MB/s \n",
            "\u001b[?25hCollecting platformdirs<3,>=2\n",
            "  Downloading platformdirs-2.5.2-py3-none-any.whl (14 kB)\n",
            "Collecting distlib<1,>=0.3.1\n",
            "  Downloading distlib-0.3.4-py2.py3-none-any.whl (461 kB)\n",
            "\u001b[K     |████████████████████████████████| 461 kB 75.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<4,>=3.2 in /usr/local/lib/python3.7/dist-packages (from virtualenv>=20.0.8->pre-commit->finrl==0.3.5) (3.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (8.13.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (1.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->finrl==0.3.5) (0.7.1)\n",
            "Requirement already satisfied: click<=8.0.4,>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (7.1.2)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (3.17.3)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (4.3.3)\n",
            "Collecting grpcio<=1.43.0,>=1.28.1\n",
            "  Downloading grpcio-1.43.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.1 MB 52.1 MB/s \n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.12-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 51.4 MB/s \n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting prometheus-client<0.14.0,>=0.7.1\n",
            "  Downloading prometheus_client-0.13.1-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.9 MB/s \n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.4-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[K     |████████████████████████████████| 201 kB 75.9 MB/s \n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0b1.tar.gz (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 260 kB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (5.2.1)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.9.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 69.1 MB/s \n",
            "\u001b[?25hCollecting nvidia-ml-py3>=7.352.0\n",
            "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat>=1.0.0b1->ray[default]->finrl==0.3.5) (5.4.8)\n",
            "Collecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]->finrl==0.3.5) (5.7.1)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]->finrl==0.3.5) (0.18.1)\n",
            "Collecting opencensus-context>=0.1.2\n",
            "  Downloading opencensus_context-0.1.2-py2.py3-none-any.whl (4.4 kB)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]->finrl==0.3.5) (1.31.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (1.56.2)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (1.35.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (4.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]->finrl==0.3.5) (0.4.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from ray[default]->finrl==0.3.5) (0.8.9)\n",
            "Collecting gym>=0.17\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 50.5 MB/s \n",
            "\u001b[?25hCollecting ale-py~=0.7.4\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 51.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (7.1.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from stable-baselines3[extra]->finrl==0.3.5) (2.8.0)\n",
            "Collecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->stable-baselines3[extra]->finrl==0.3.5) (4.64.0)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (3.3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (0.4.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.1.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->stable-baselines3[extra]->finrl==0.3.5) (3.2.0)\n",
            "Collecting mock\n",
            "  Downloading mock-4.0.3-py3-none-any.whl (28 kB)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 47.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from yfinance->finrl==0.3.5) (0.0.10)\n",
            "Collecting lxml\n",
            "  Downloading lxml-4.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 47.6 MB/s \n",
            "\u001b[?25hCollecting requests>=2.18.4\n",
            "  Using cached requests-2.28.0-py3-none-any.whl (62 kB)\n",
            "Building wheels for collected packages: finrl, elegantrl, pyfolio, empyrical, exchange-calendars, gputil, thriftpy2, gpustat, nvidia-ml-py3, gym, AutoROM.accept-rom-license\n",
            "  Building wheel for finrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.5-py3-none-any.whl size=2740886 sha256=1db15858ba5ab725286ad4efba2ef3ee3933ac44f83d0c6c21e460697d8cf43a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tkqs3__2/wheels/68/0f/0a/2bcdb0d0328bcce6893b6d958945fd9f0ebc505cde730c1cef\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=elegantrl-0.3.3-py3-none-any.whl size=77205 sha256=68a11aae747cef00b81bc82045d3256f5e69331b35017f27faddf4bf19663480\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tkqs3__2/wheels/99/85/5e/86cb3a9f47adfca5e248295e93113e1b298d60883126d62c84\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75774 sha256=8f4982f10770f369965047fb2ff41116b4740d8cbbeaff6973390880e3df54e4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tkqs3__2/wheels/ef/09/e5/2c1bf37c050d22557c080deb1be986d06424627c04aeca19b9\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39780 sha256=0e31f535b64d7b3a2db5af34490f7b1dda6c6e0883a3bd5fd50ca6598878ebce\n",
            "  Stored in directory: /root/.cache/pip/wheels/d9/91/4b/654fcff57477efcf149eaca236da2fce991526cbab431bf312\n",
            "  Building wheel for exchange-calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for exchange-calendars: filename=exchange_calendars-3.6.3-py3-none-any.whl size=182636 sha256=b76b17f26bac8516d50c115eca77e78f4a105e3861516605a1af4ae87fa9a441\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/a3/19/b4611514d34ffd61d13aef10fefc2dcaf3754145121ceba647\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=c18ef8c26dc92f9f08bae21c248bf28702c948c65bdd9f7d76096430923bd8e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.14-cp37-cp37m-linux_x86_64.whl size=953111 sha256=0bf01308b112d0be273f2ba3f9ad464def36a271fb7bed16b1c4d730f3350fc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/f5/49/9c0d851aa64b58db72883cf9393cc824d536bdf13f5c83cff4\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0b1-py3-none-any.whl size=15979 sha256=191797fc588ed51315f2e69e2bda6fa70893874073907281d5d48d412bd2f308\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/16/e2/3e2437fba4c4b6a97a97bd96fce5d14e66cff5c4966fb1cc8c\n",
            "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19190 sha256=286a600897095ccb5f5e534a81c93e6de873f81ce1fd214b0054084e208e2fbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/99/da/c34f202dc8fd1dffd35e0ecf1a7d7f8374ca05fbcbaf974b83\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616824 sha256=49f85d73983f84cfca7e1bf519103f225007d860162b9c74bfe3c34a8303aced\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/ee/9c/36bfe3e079df99acf5ae57f4e3464ff2771b34447d6d2f2148\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=d6346d88fdc9d4aa2a37f27ad7f1650bd58879a822d8557de183c0ce99c0ada7\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built finrl elegantrl pyfolio empyrical exchange-calendars gputil thriftpy2 gpustat nvidia-ml-py3 gym AutoROM.accept-rom-license\n",
            "Installing collected packages: setuptools, requests, multidict, frozenlist, yarl, platformdirs, lxml, distlib, asynctest, async-timeout, aiosignal, virtualenv, PyYAML, pycares, ply, opencensus-context, nvidia-ml-py3, msgpack, gym, grpcio, blessed, AutoROM.accept-rom-license, autorom, aiohttp, websockets, websocket-client, toml, thriftpy2, tensorboardX, stable-baselines3, ray, pymysql, pyluach, pybullet, py-spy, psycopg2-binary, prometheus-client, opencensus, nodeenv, mock, identify, gpustat, empyrical, deprecation, cryptography, colorful, cfgv, box2d-py, ale-py, aiohttp-cors, aiodns, yfinance, wrds, stockstats, pyfolio, pre-commit, lz4, jqdatasdk, gputil, exchange-calendars, elegantrl, ccxt, alpaca-trade-api, finrl\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 57.4.0\n",
            "    Uninstalling setuptools-57.4.0:\n",
            "      Successfully uninstalled setuptools-57.4.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: lxml\n",
            "    Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.4\n",
            "    Uninstalling msgpack-1.0.4:\n",
            "      Successfully uninstalled msgpack-1.0.4\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.46.3\n",
            "    Uninstalling grpcio-1.46.3:\n",
            "      Successfully uninstalled grpcio-1.46.3\n",
            "  Attempting uninstall: prometheus-client\n",
            "    Found existing installation: prometheus-client 0.14.1\n",
            "    Uninstalling prometheus-client-0.14.1:\n",
            "      Successfully uninstalled prometheus-client-0.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.28.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 PyYAML-6.0 aiodns-3.0.0 aiohttp-3.8.1 aiohttp-cors-0.7.0 aiosignal-1.2.0 ale-py-0.7.5 alpaca-trade-api-2.3.0 async-timeout-4.0.2 asynctest-0.13.0 autorom-0.4.2 blessed-1.19.1 box2d-py-2.3.8 ccxt-1.66.32 cfgv-3.3.1 colorful-0.5.4 cryptography-37.0.2 deprecation-2.1.0 distlib-0.3.4 elegantrl-0.3.3 empyrical-0.5.5 exchange-calendars-3.6.3 finrl-0.3.5 frozenlist-1.3.0 gpustat-1.0.0b1 gputil-1.4.0 grpcio-1.43.0 gym-0.21.0 identify-2.5.1 jqdatasdk-1.8.10 lxml-4.9.0 lz4-4.0.1 mock-4.0.3 msgpack-1.0.3 multidict-6.0.2 nodeenv-1.7.0 nvidia-ml-py3-7.352.0 opencensus-0.9.0 opencensus-context-0.1.2 platformdirs-2.5.2 ply-3.11 pre-commit-2.19.0 prometheus-client-0.13.1 psycopg2-binary-2.9.3 py-spy-0.3.12 pybullet-3.2.5 pycares-4.2.1 pyfolio-0.9.2+75.g4b901f6 pyluach-2.0.0 pymysql-1.0.2 ray-1.13.0 requests-2.28.0 setuptools-59.5.0 stable-baselines3-1.5.0 stockstats-0.4.1 tensorboardX-2.5.1 thriftpy2-0.4.14 toml-0.10.2 virtualenv-20.15.1 websocket-client-1.3.3 websockets-10.3 wrds-3.1.1 yarl-1.7.2 yfinance-0.1.72\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pkg_resources"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting HEBO>=0.2.0\n",
            "  Downloading HEBO-0.3.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 15.2 MB/s \n",
            "\u001b[?25hCollecting pymoo>=0.5.0\n",
            "  Downloading pymoo-0.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 65.4 MB/s \n",
            "\u001b[?25hCollecting catboost>=0.24.4\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting GPy>=1.9.9\n",
            "  Downloading GPy-1.10.0.tar.gz (959 kB)\n",
            "\u001b[K     |████████████████████████████████| 959 kB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from HEBO>=0.2.0) (1.0.2)\n",
            "Collecting gpytorch>=1.4.0\n",
            "  Downloading gpytorch-1.7.0-py2.py3-none-any.whl (353 kB)\n",
            "\u001b[K     |████████████████████████████████| 353 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from HEBO>=0.2.0) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from HEBO>=0.2.0) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from HEBO>=0.2.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (1.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (3.2.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (5.5.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (0.10.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (1.4.1)\n",
            "Collecting paramz>=0.9.0\n",
            "  Downloading paramz-0.9.5.tar.gz (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 11.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from GPy>=1.9.9->HEBO>=0.2.0) (0.29.30)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->HEBO>=0.2.0) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->HEBO>=0.2.0) (2.8.2)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.7/dist-packages (from paramz>=0.9.0->GPy>=1.9.9->HEBO>=0.2.0) (4.4.2)\n",
            "Collecting cma==2.7\n",
            "  Downloading cma-2.7.0-py2.py3-none-any.whl (239 kB)\n",
            "\u001b[K     |████████████████████████████████| 239 kB 61.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from pymoo>=0.5.0->HEBO>=0.2.0) (1.4)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->pymoo>=0.5.0->HEBO>=0.2.0) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.24.4->HEBO>=0.2.0) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.24.4->HEBO>=0.2.0) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.24.4->HEBO>=0.2.0) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost>=0.24.4->HEBO>=0.2.0) (4.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->HEBO>=0.2.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->HEBO>=0.2.0) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.24.4->HEBO>=0.2.0) (8.0.1)\n",
            "Building wheels for collected packages: GPy, paramz\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.10.0-cp37-cp37m-linux_x86_64.whl size=2565089 sha256=1adaf5d916447af2991f2b5397e69117c8f62ad4e46f56624e342247c4aef5e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/18/28/dd1ce0192a81b71a3b086fd952511d088b21e8359ea496860a\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-py3-none-any.whl size=102566 sha256=8c05b936af0a79c224eb6ed376794d91829c257b87e34e8cb044e48519565067\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/95/f5/ce28482da28162e6028c4b3a32c41d147395825b3cd62bc810\n",
            "Successfully built GPy paramz\n",
            "Installing collected packages: paramz, cma, pymoo, gpytorch, GPy, catboost, HEBO\n",
            "Successfully installed GPy-1.10.0 HEBO-0.3.2 catboost-1.0.6 cma-2.7.0 gpytorch-1.7.0 paramz-0.9.5 pymoo-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/NicoleRichards1998/FinRL.git\n",
        "!pip install 'HEBO>=0.2.0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WjL3e73MnNc",
        "outputId": "3fc9c74c-2a05-492e-c2ed-7b1bb6a55d0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting up colab environment\n",
            "\u001b[33mWARNING: ray 1.13.0 does not provide the extra 'debug'\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "print(\"Setting up colab environment\")\n",
        "!pip uninstall -y -q pyarrow\n",
        "!pip install -q -U ray[tune]\n",
        "!pip install -q ray[debug]\n",
        "\n",
        "# A hack to force the runtime to restart, needed to include the above dependencies.\n",
        "print(\"Done installing! Restarting via forced crash (this is not an issue).\")\n",
        "import os\n",
        "os._exit(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--6Kx8I21erH"
      },
      "source": [
        "## Import related modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7I7zsyYfoLJ",
        "outputId": "0b6975fe-d381-4cef-da88-cd8fb80ae9ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyfolio/pos.py:27: UserWarning: Module \"zipline.assets\" not found; multipliers will not be applied to position notionals.\n",
            "  'Module \"zipline.assets\" not found; multipliers will not be applied'\n"
          ]
        }
      ],
      "source": [
        "from finrl.finrl_meta.env_stock_trading.env_stocktrading_np import EndRewardStockTradingEnv as StockTradingEnv1\n",
        "from finrl.finrl_meta.env_stock_trading.env_stocktrading_np import StockTradingEnv\n",
        "from finrl.finrl_meta.env_stock_trading.env_stocktrading_np import ChangedStockTradingEnv as StockTradingEnv2\n",
        "\n",
        "from finrl.finrl_meta.env_stock_trading.env_stock_papertrading import AlpacaPaperTrading\n",
        "from finrl.finrl_meta.data_processor import DataProcessor\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "from finrl.agents.rllib.models import DRLAgent as DRLAgent_rllib\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import ray\n",
        "\n",
        "from ray.rllib.agents.a3c import a2c\n",
        "from ray.rllib.agents.ddpg import ddpg, td3\n",
        "from ray.rllib.agents.ppo import ppo\n",
        "from ray.rllib.agents.ppo.ppo import PPOTrainer\n",
        "from ray.rllib.agents.ddpg import DDPGTrainer\n",
        "from ray.rllib.agents.a3c import A2CTrainer\n",
        "from ray.rllib.agents.sac import sac\n",
        "from ray.tune.logger import (\n",
        "    CSVLoggerCallback,\n",
        "    JsonLoggerCallback,\n",
        "    JsonLogger,\n",
        "    CSVLogger,\n",
        "    TBXLoggerCallback,\n",
        "    TBXLogger,\n",
        "    UnifiedLogger\n",
        ")\n",
        "from ray.tune.logger import pretty_print\n",
        "\n",
        "from ray.tune.logger import pretty_print\n",
        "from ray import tune\n",
        "from ray.tune.suggest import ConcurrencyLimiter\n",
        "from ray.tune.schedulers import AsyncHyperBandScheduler, PopulationBasedTraining\n",
        "from ray.tune.suggest.hebo import HEBOSearch\n",
        "from ray.tune.suggest.optuna import OptunaSearch\n",
        "\n",
        "from google.colab import files\n",
        "from datetime import date, timedelta, datetime\n",
        "\n",
        "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
        "from pandas.core.arrays import string_\n",
        "\n",
        "import pytz\n",
        "import exchange_calendars as tc\n",
        "\n",
        "from stockstats import StockDataFrame as Sdf\n",
        "\n",
        "import psutil\n",
        "import ray\n",
        "ray._private.utils.get_system_memory = lambda: psutil.virtual_memory().total"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcRhvYr-jUrI"
      },
      "source": [
        "## Set variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UA0ldsKSjPJs"
      },
      "outputs": [],
      "source": [
        "model_algorithm = 'ppo'\n",
        "starting_capital = 1e6\n",
        "\n",
        "Number_Train_Days = 10\n",
        "\n",
        "Number_Test_Days = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hL6l6e5z2pfy"
      },
      "outputs": [],
      "source": [
        "JSEIndexes = [ 'ACL' ]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "JSEIndexes = [ 'ACL', 'WHL' ]"
      ],
      "metadata": {
        "id": "pMF29cauubVU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "JSEIndexes = [ 'ACL', 'SSW' ]"
      ],
      "metadata": {
        "id": "RqXczJmBuz9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "JSEIndexes = [ 'ACL', 'GFI' ]"
      ],
      "metadata": {
        "id": "xn3bsa4Nu3Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "JSEIndexes = [ 'ACL', 'HAR' ]"
      ],
      "metadata": {
        "id": "i-mrD26BvZ6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "JSEIndexes = [ 'ACL', 'WHL' ]"
      ],
      "metadata": {
        "id": "J-47U8BEvb0T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtaELsI5CBdr"
      },
      "outputs": [],
      "source": [
        "JSEIndexes = \n",
        "['ACL',0\n",
        " 'AVI',1\n",
        " 'BLU',2\n",
        " 'CML',3\n",
        " 'EXX',4\n",
        " 'FSR',5\n",
        " 'GFI',6\n",
        " 'HAR',7\n",
        " 'LAB',8\n",
        " 'LHC',9\n",
        " 'MRF',10\n",
        " 'MTN',11\n",
        " 'NED',12\n",
        " 'NPK',13\n",
        " 'OMU',14\n",
        " 'PPC',15\n",
        " 'PPE',16\n",
        " 'PPH',17\n",
        " 'RMH',18\n",
        " 'SBK',19\n",
        " 'SNH',20\n",
        " 'SOL',21\n",
        " 'SPG',22\n",
        " 'SSW',23\n",
        " 'TCP',24\n",
        " 'TGA',25\n",
        " 'TRU',26\n",
        " 'TSG',27\n",
        " 'WHL',28\n",
        " 'WSL']29"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9D-xi0Pq25RU"
      },
      "outputs": [],
      "source": [
        "ticker_list = JSEIndexes\n",
        "action_dim = len(ticker_list)\n",
        "\n",
        "INDICATORS = ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
        "tech_indicator_list = INDICATORS\n",
        "env = StockTradingEnv2\n",
        "\n",
        "# amount + (turbulence, turbulence_bool) + (price, shares, cd (holding time)) * stock_dim + tech_dim\n",
        "state_dim = 1 + 2 + 3 * action_dim + len(INDICATORS) * action_dim\n",
        "#state_dim = 1 + 2 + 3 * action_dim\n",
        "\n",
        "episodes_per_day = 150\n",
        "tr_batch_size = episodes_per_day*480\n",
        "\n",
        "rllib_params = {\"lr\": 5e-5, \"train_batch_size\": tr_batch_size, \"gamma\": 0.99}\n",
        "\n",
        "MODELS = {\"a2c\": a2c, \"ddpg\": ddpg, \"td3\": td3, \"sac\": sac, \"ppo\": ppo}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eW0UDAXI1nEa"
      },
      "source": [
        "# Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Reci0sr_28X",
        "outputId": "39bc62d2-02f3-4fca-909d-f7a2b0ea69c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/csvfiles\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/csvfiles/\n",
        "\n",
        "data_df = pd.read_csv(\"JSE_Minute_Data_With_Turbulance_Indicator.csv\")\n",
        "\n",
        "df = data_df.copy()\n",
        "df = df.sort_values(by=[\"tic\", \"date\"])\n",
        "x = 9620\n",
        "dic_tickers = {}\n",
        "\n",
        "for i in range(30):\n",
        "\n",
        "  dic_tickers[i] = df.iloc[(i*x):((i+1)*x),]\n",
        "\n",
        "trading_days = pd.date_range(start = '02/28/22', end = '03/25/22')\n",
        "\n",
        "trading_days_List = trading_days[0:].strftime('%m/%d/%y').to_numpy().tolist()\n",
        "count = 0\n",
        "delete_number = 0\n",
        "while count < 26:\n",
        "    if (trading_days[count].weekday()>=5):\n",
        "      del trading_days_List[delete_number]\n",
        "      delete_number = delete_number - 1\n",
        "    count = count + 1\n",
        "    delete_number = delete_number + 1 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NJc8McrJwVvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN36X4Wfa6uW"
      },
      "source": [
        "Single ticker:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "emwlGr3iVI-r"
      },
      "outputs": [],
      "source": [
        "x = 481\n",
        "df = dic_tickers[0].copy()\n",
        "df = df.reset_index(drop=True)\n",
        "dic = {}\n",
        "\n",
        "for j in range(len(df)):\n",
        "    df['date'][j] = datetime.strptime(df['date'][j], '%m/%d/%y %H:%M')\n",
        "df = df.sort_values(by=[\"date\"])\n",
        "\n",
        "for i in range(20):\n",
        "  \n",
        "  dic[i] = df.iloc[(i*x):((i+1)*x),]\n",
        "  dic[i] = dic[i].sort_values(by=[\"tic\", \"date\"])\n",
        "  dic[i] = dic[i].reset_index(drop=True)\n",
        "  #for j in range(len(dic[i])):\n",
        "  #  dic[i]['date'][j] = datetime.strptime(dic[i]['date'][j], '%m/%d/%y %H:%M')\n",
        "  dic[i] = dic[i].sort_values(by=[\"date\"])\n",
        "\n",
        "del dic[15]\n",
        "dic = dict(enumerate(dic[x] for x in sorted(dic)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3jw9HmrH5Ts"
      },
      "source": [
        "Two tickers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PonDmvuW7IuH"
      },
      "outputs": [],
      "source": [
        "x = 962\n",
        "df1 = dic_tickers[0].copy()\n",
        "df2 = dic_tickers[7].copy()\n",
        "df3 = df1.append(df2, ignore_index=True)\n",
        "df = df3.reset_index(drop=True)\n",
        "\n",
        "dic = {}\n",
        "\n",
        "for j in range(len(df)):\n",
        "    df['date'][j] = datetime.strptime(df['date'][j], '%m/%d/%y %H:%M')\n",
        "df = df.sort_values(by=[\"date\"])\n",
        "\n",
        "for i in range(20):\n",
        "  \n",
        "  dic[i] = df.iloc[(i*x):((i+1)*x),]\n",
        "  dic[i] = dic[i].sort_values(by=[\"tic\", \"date\"])\n",
        "  dic[i] = dic[i].reset_index(drop=True)\n",
        "  #for j in range(len(dic[i])):\n",
        "  #  dic[i]['date'][j] = datetime.strptime(dic[i]['date'][j], '%m/%d/%y %H:%M')\n",
        "  dic[i] = dic[i].sort_values(by=[\"date\"])\n",
        "\n",
        "del dic[15]\n",
        "dic = dict(enumerate(dic[x] for x in sorted(dic)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHgAnFDZa-0J"
      },
      "source": [
        "Multiple tickers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrTQZJ4B5r3y"
      },
      "outputs": [],
      "source": [
        "x = 14430\n",
        "df = data_df.copy()\n",
        "dic = {}\n",
        "\n",
        "for i in range(20):\n",
        "\n",
        "  dic[i] = df.iloc[(i*x):((i+1)*x),]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bCCMqVmwm5Y6"
      },
      "outputs": [],
      "source": [
        "def df_to_array(df, if_vix):\n",
        "        df = df.copy()\n",
        "        unique_ticker = df.tic.unique()\n",
        "        if_first_time = True\n",
        "        for tic in unique_ticker:\n",
        "            if if_first_time:\n",
        "                price_array = df[df.tic == tic][[\"close\"]].values\n",
        "                tech_array = df[df.tic == tic][tech_indicator_list].values\n",
        "                if if_vix:\n",
        "                    turbulence_array = df[df.tic == tic][\"VIXY\"].values\n",
        "                else:\n",
        "                    turbulence_array = df[df.tic == tic][\"turbulence\"].values\n",
        "                if_first_time = False\n",
        "            else:\n",
        "                price_array = np.hstack(\n",
        "                    [price_array, df[df.tic == tic][[\"close\"]].values]\n",
        "                )\n",
        "                tech_array = np.hstack(\n",
        "                    [tech_array, df[df.tic == tic][tech_indicator_list].values]\n",
        "                )\n",
        "        print(\"Successfully transformed into array\")\n",
        "        return price_array, tech_array, turbulence_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LDbA5YIj3kpv"
      },
      "outputs": [],
      "source": [
        "def get_config_Train(dic, Number_Days):  \n",
        "\n",
        "    env_config = []\n",
        "\n",
        "    for index in range(Number_Days):\n",
        "\n",
        "      print(index)\n",
        "\n",
        "      price_array, tech_array, turbulence_array = df_to_array(dic[index], False)\n",
        "\n",
        "      config = {\n",
        "          \"price_array\": price_array,\n",
        "          \"tech_array\": tech_array,\n",
        "          \"turbulence_array\": turbulence_array,\n",
        "          \"if_train\": True,\n",
        "      }\n",
        "\n",
        "      env_config.append(config)\n",
        "\n",
        "    return env_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFThuQm8xjPP",
        "outputId": "d6b01ffc-5fcd-4d6d-a038-75c7de2baa1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Successfully transformed into array\n",
            "1\n",
            "Successfully transformed into array\n",
            "2\n",
            "Successfully transformed into array\n",
            "3\n",
            "Successfully transformed into array\n",
            "4\n",
            "Successfully transformed into array\n",
            "5\n",
            "Successfully transformed into array\n",
            "6\n",
            "Successfully transformed into array\n",
            "7\n",
            "Successfully transformed into array\n",
            "8\n",
            "Successfully transformed into array\n",
            "9\n",
            "Successfully transformed into array\n"
          ]
        }
      ],
      "source": [
        "train_env_config = get_config_Train(dic, Number_Train_Days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MxbcfM5cbKhu"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "import json\n",
        "\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "from ray.tune.utils.util import SafeFallbackEncoder\n",
        "from ray.tune.logger import Logger\n",
        "\n",
        "EXPR_TRACK_FILE = \"episode_tracking.json\"\n",
        "CUSTOM_RESULTS_DIR = '/content/drive/MyDrive/TrainingData'\n",
        "DEFAULT_LOGGERS = (JsonLogger, CSVLogger, TBXLogger)\n",
        "\n",
        "class CustomLogger(Logger):\n",
        "    \"\"\"Logs custom results in json format.\"\"\"\n",
        "\n",
        "    def _init(self):\n",
        "        self.update_config(self.config)\n",
        "        logger_config = self.config.get(\"logger_config\")\n",
        "        filename = EXPR_TRACK_FILE\n",
        "        if logger_config:\n",
        "            filename = logger_config.get(\"filename\") or filename\n",
        "        local_file = os.path.join(self.logdir, filename)\n",
        "        self.local_out = open(local_file, \"a\")\n",
        "\n",
        "    def on_result(self, result: Dict):\n",
        "        tracking_data = result[\"episode_media\"]\n",
        "        if not tracking_data:\n",
        "            return\n",
        "        json.dump(tracking_data, self, cls=SafeFallbackEncoder)\n",
        "        self.write(\"\\n\")\n",
        "        self.local_out.flush()\n",
        "\n",
        "    def write(self, b):\n",
        "        self.local_out.write(b)\n",
        "\n",
        "    def flush(self):\n",
        "        if not self.local_out.closed:\n",
        "            self.local_out.flush()\n",
        "\n",
        "    def close(self):\n",
        "        self.local_out.close()\n",
        "\n",
        "    def update_config(self, config: Dict):\n",
        "        self.config = config\n",
        "\n",
        "def custom_logger_creator(config):\n",
        "    \"\"\"Creates a Unified logger with a default logdir prefix\n",
        "    containing the agent name and the env id\n",
        "    \"\"\"\n",
        "    timestr = datetime.today().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    logdir_prefix = \"{}_{}_{}\".format(\"PPO\", \"HSP\", timestr)\n",
        "    if not os.path.exists(CUSTOM_RESULTS_DIR):\n",
        "        os.makedirs(CUSTOM_RESULTS_DIR)\n",
        "    logdir = tempfile.mkdtemp(\n",
        "        prefix=logdir_prefix, dir=CUSTOM_RESULTS_DIR)\n",
        "    loggers = list(DEFAULT_LOGGERS)\n",
        "    loggers.append(CustomLogger)\n",
        "    return UnifiedLogger(config, logdir, loggers=loggers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlcHCgsCbGzV"
      },
      "source": [
        "# Tune the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iv2m0NwAb29h"
      },
      "outputs": [],
      "source": [
        "day = 0\n",
        "\n",
        "def sample_ppo_params():\n",
        "  return {\n",
        "      \"clip_param\": tune.choice([ 0.1, 0.2, 0.3, 0.4, 0.5, 0.6 ]),\n",
        "      \"lambda\": tune.loguniform(0.9, 1),\n",
        "      \"lr\": tune.loguniform(5e-6, 0.003),\n",
        "      \"gamma\": tune.loguniform(0.9, 0.9997),\n",
        "      \"train_batch_size\": 2400\n",
        "  }\n",
        "\n",
        "def sample_ddpg_params():\n",
        "  \n",
        "  return {\n",
        "  \"critic_lr\": tune.loguniform(1e-3, 1e-4),\n",
        "  \"actor_lr\": tune.loguniform(1e-3, 1e-5),\n",
        "  \"tau\": tune.loguniform(1e-5, 1e-3),\n",
        "  \"gamma\": tune.loguniform(0.9, 0.9997),\n",
        "  'obs_batch' : 128,\n",
        "  \"train_batch_size\": 960\n",
        "  }\n",
        "\n",
        "def sample_a2c_params():\n",
        "  \n",
        "  return{\n",
        "      \"lambda\": tune.choice([0.1,0.3,0.5,0.7,0.9,1.0]),\n",
        "      \"lr\": tune.loguniform(1e-4, 1e-2),\n",
        "      \"gamma\": tune.loguniform(0.9, 0.9997),\n",
        "      \"train_batch_size\": 960  \n",
        "  } \n",
        "\n",
        "from ray.tune.registry import register_env\n",
        "from ray.tune.integration.comet import CometLoggerCallback\n",
        "from ray.tune.logger import (\n",
        "    CSVLoggerCallback,\n",
        "    JsonLoggerCallback,\n",
        "    JsonLogger,\n",
        "    CSVLogger,\n",
        "    TBXLoggerCallback,\n",
        "    TBXLogger,\n",
        ")\n",
        "\n",
        "env_name = 'StockTrading_train_env'\n",
        "register_env(env_name, lambda config: env(train_env_config[day]))\n",
        "\n",
        "MODEL_TRAINER = {'a2c':A2CTrainer,'ppo':PPOTrainer,'ddpg':DDPGTrainer}\n",
        "\n",
        "if model_algorithm == \"ddpg\":\n",
        "    sample_hyperparameters = sample_ddpg_params()\n",
        "elif model_algorithm == \"ppo\":\n",
        "  sample_hyperparameters = sample_ppo_params()\n",
        "elif model_algorithm == \"a2c\":\n",
        "  sample_hyperparameters = sample_a2c_params()\n",
        "  \n",
        "def run_tune():\n",
        "\n",
        "  # maximum number of concurrent trials\n",
        "  max_concurrent = 8\n",
        "\n",
        "  algo = HEBOSearch(\n",
        "        # space = space, # If you want to set the space\n",
        "        #points_to_evaluate=previously_run_params,\n",
        "        #evaluated_rewards=known_rewards,\n",
        "        random_state_seed=123,  # for reproducibility\n",
        "        max_concurrent=max_concurrent,\n",
        "    )\n",
        "\n",
        "  scheduler = AsyncHyperBandScheduler(grace_period=4)\n",
        "\n",
        "  training_iterations = 100\n",
        "  num_samples = 25\n",
        "\n",
        "  analysis = tune.run(\n",
        "        MODEL_TRAINER[model_algorithm],\n",
        "        metric=\"episode_reward_mean\", #The metric to optimize for tuning\n",
        "        mode=\"max\", #Maximize the metric\n",
        "        #name='B1',\n",
        "        search_alg=algo,\n",
        "        scheduler=scheduler,\n",
        "        num_samples=num_samples,\n",
        "        keep_checkpoints_num = num_samples,\n",
        "        stop = {'training_iteration':training_iterations},\n",
        "        checkpoint_score_attr ='episode_reward_mean',#Only store keep_checkpoints_num trials based on this score\n",
        "        checkpoint_freq=training_iterations,\n",
        "        verbose=1,\n",
        "        local_dir=\"./tuned_models\",#Saving tensorboard plots\n",
        "        callbacks=[\n",
        "          TBXLoggerCallback()\n",
        "        ],\n",
        "        raise_on_failed_trial=False,\n",
        "        config = {\n",
        "                **sample_hyperparameters,\n",
        "                'env':'StockTrading_train_env',\n",
        "                'framework':'tf2',\n",
        "                \"eager_tracing\" : False,\n",
        "                \"num_workers\": 1,\n",
        "                # Total GPU usage: num_gpus (trainer proc) + num_gpus_per_worker (workers)\n",
        "                #\"num_gpus_per_worker\": 0.25,\n",
        "                # this corresponds to the number of learner GPUs used,\n",
        "                # not the total used for the environments/rollouts\n",
        "                \"num_gpus\": 1,\n",
        "                \"num_envs_per_worker\": 1,\n",
        "                #\"callbacks\": LoggingCallbacks,\n",
        "                \"model\":{\n",
        "                    \"use_lstm\": True,\n",
        "                    \"lstm_cell_size\": 256,\n",
        "                    \"lstm_use_prev_action\": True,\n",
        "                    \"lstm_use_prev_reward\": True,\n",
        "                  }\n",
        "                },\n",
        "  )\n",
        "\n",
        "\n",
        "  print(\"Best hyperparameter: \", analysis.best_config)\n",
        "  #print(\"Training: \", analysis.trails)\n",
        "  return analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNp3EY_zdYLr"
      },
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "dl4-krvYVz1A",
        "outputId": "82fe8ee5-fe7a-4d6e-d6c5-a21fb2035da5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "== Status ==<br>Current time: 2022-06-29 10:32:07 (running for 00:00:06.97)<br>Memory usage on this node: 2.3/12.7 GiB<br>Using AsyncHyperBand: num_stopped=0\n",
              "Bracket: Iter 64.000: None | Iter 16.000: None | Iter 4.000: None<br>Resources requested: 2.0/2 CPUs, 1.0/1 GPUs, 0.0/7.34 GiB heap, 0.0/3.67 GiB objects (0.0/1.0 accelerator_type:P100)<br>Result logdir: /content/drive/MyDrive/csvfiles/tuned_models/DDPGTrainer_2022-06-29_10-32-00<br>Number of trials: 1/25 (1 RUNNING)<br><br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-06-29 10:32:07,782\tERROR tune.py:743 -- Trials did not complete: [DDPGTrainer_StockTrading_train_env_b5a0634c]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameter:  {'critic_lr': 0.001000000000000001, 'actor_lr': 0.001000000000000001, 'tau': 1e-05, 'gamma': 0.9, 'obs_batch': 128, 'train_batch_size': 960, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': False, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}\n"
          ]
        }
      ],
      "source": [
        "analysis = run_tune()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'HEBO>=0.2.0'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZgmbvhRtUi3",
        "outputId": "367f2ddd-78ed-4174-81a4-938ad30042b7"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting HEBO>=0.2.0\n",
            "  Downloading HEBO-0.3.2-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 11.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from HEBO>=0.2.0) (1.3.5)\n",
            "Collecting pymoo>=0.5.0\n",
            "  Downloading pymoo-0.5.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 60.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.7/dist-packages (from HEBO>=0.2.0) (1.0.2)\n",
            "Collecting GPy>=1.9.9\n",
            "  Downloading GPy-1.10.0.tar.gz (959 kB)\n",
            "\u001b[K     |████████████████████████████████| 959 kB 55.7 MB/s \n",
            "\u001b[?25hCollecting catboost>=0.24.4\n",
            "  Downloading catboost-1.0.6-cp37-none-manylinux1_x86_64.whl (76.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 76.6 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting gpytorch>=1.4.0\n",
            "  Downloading gpytorch-1.7.0-py2.py3-none-any.whl (353 kB)\n",
            "\u001b[K     |████████████████████████████████| 353 kB 67.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from HEBO>=0.2.0) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from HEBO>=0.2.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (1.15.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (0.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (5.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (1.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost>=0.24.4->HEBO>=0.2.0) (3.2.2)\n",
            "Collecting paramz>=0.9.0\n",
            "  Downloading paramz-0.9.5.tar.gz (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from GPy>=1.9.9->HEBO>=0.2.0) (0.29.30)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->HEBO>=0.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->HEBO>=0.2.0) (2022.1)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.7/dist-packages (from paramz>=0.9.0->GPy>=1.9.9->HEBO>=0.2.0) (4.4.2)\n",
            "Collecting cma==2.7\n",
            "  Downloading cma-2.7.0-py2.py3-none-any.whl (239 kB)\n",
            "\u001b[K     |████████████████████████████████| 239 kB 64.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: autograd>=1.3 in /usr/local/lib/python3.7/dist-packages (from pymoo>=0.5.0->HEBO>=0.2.0) (1.4)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd>=1.3->pymoo>=0.5.0->HEBO>=0.2.0) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.24.4->HEBO>=0.2.0) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.24.4->HEBO>=0.2.0) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost>=0.24.4->HEBO>=0.2.0) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->catboost>=0.24.4->HEBO>=0.2.0) (4.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->HEBO>=0.2.0) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22->HEBO>=0.2.0) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost>=0.24.4->HEBO>=0.2.0) (8.0.1)\n",
            "Building wheels for collected packages: GPy, paramz\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.10.0-cp37-cp37m-linux_x86_64.whl size=2565132 sha256=6fdc1760d20974ea9433741ef308d3444b0d40e1ca9d8b7533bc576c433aee4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/18/28/dd1ce0192a81b71a3b086fd952511d088b21e8359ea496860a\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-py3-none-any.whl size=102566 sha256=62ff103b5695fcffb664eae067bcd70fd5c72ae72dc00b8f06fc3db835218242\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/95/f5/ce28482da28162e6028c4b3a32c41d147395825b3cd62bc810\n",
            "Successfully built GPy paramz\n",
            "Installing collected packages: paramz, cma, pymoo, gpytorch, GPy, catboost, HEBO\n",
            "Successfully installed GPy-1.10.0 HEBO-0.3.2 catboost-1.0.6 cma-2.7.0 gpytorch-1.7.0 paramz-0.9.5 pymoo-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analysis.best_config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCyC36t0EFyW",
        "outputId": "0987b034-f959-4b0b-9394-65d134f40d1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clip_param': 0.1,\n",
              " 'eager_tracing': False,\n",
              " 'env': 'StockTrading_train_env',\n",
              " 'framework': 'tf2',\n",
              " 'gamma': 0.9037485846525093,\n",
              " 'lambda': 0.9386668141475626,\n",
              " 'lr': 5.000197729565842e-06,\n",
              " 'model': {'lstm_cell_size': 256,\n",
              "  'lstm_use_prev_action': True,\n",
              "  'lstm_use_prev_reward': True,\n",
              "  'use_lstm': True},\n",
              " 'num_envs_per_worker': 1,\n",
              " 'num_gpus': 1,\n",
              " 'num_workers': 1,\n",
              " 'train_batch_size': 2400}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYRdcsClcIOQ"
      },
      "source": [
        "# Train the agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "5RFyC8YpdT3T"
      },
      "outputs": [],
      "source": [
        "#B1\n",
        "best_config = {}\n",
        "best_config[0] = {'clip_param': 0.2, 'lambda': 0.9740037464252967, 'lr': 2.4746160019198826e-05, 'gamma': 0.9239517770930289, 'train_batch_size': 2400, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp6pf4s2yDm8"
      },
      "outputs": [],
      "source": [
        "#B2\n",
        "best_config = {}\n",
        "best_config[0] = {'clip_param': 0.1, 'lambda': 0.9, 'lr': 4.9999999999999996e-06, 'gamma': 0.9, 'train_batch_size': 2400, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRNKeTgvh4tx"
      },
      "outputs": [],
      "source": [
        "#B3\n",
        "best_config = {}\n",
        "best_config[0] = {'clip_param': 0.4, 'lambda': 0.9612601554586079, 'lr': 1.1123434725658893e-05, 'gamma': 0.9866572109841178, 'train_batch_size': 2400, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1CmUqtUru6t"
      },
      "outputs": [],
      "source": [
        "#B4\n",
        "best_config = {}\n",
        "best_config[0] = {'clip_param': 0.1, 'lambda': 0.9009927357612731, 'lr': 0.00010502434259151515, 'gamma': 0.9538296116220573, 'train_batch_size': 2400, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoKvqisIoGW7"
      },
      "outputs": [],
      "source": [
        "#B5\n",
        "best_config = {}\n",
        "best_config[0] = {'clip_param': 0.1, 'lambda': 0.9700218400062812, 'lr': 0.00014620699838982138, 'gamma': 0.9951363917420465, 'train_batch_size': 2400, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrAQOXCDFQfi"
      },
      "outputs": [],
      "source": [
        "#B6\n",
        "best_config = {}\n",
        "best_config[0] = {'clip_param': 0.5, 'lambda': 0.9070509140062014, 'lr': 0.0003133465721916071, 'gamma': 0.939069703010826, 'train_batch_size': 2400, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKRs6_EmHvp4"
      },
      "outputs": [],
      "source": [
        "#C1\n",
        "best_config = {}\n",
        "best_config[0] = {'lambda': 0.9, 'lr': 0.0001519697811702668, 'gamma': 0.9748814421424221, 'train_batch_size': 960, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aYOxE5h8RVe"
      },
      "outputs": [],
      "source": [
        "#C3\n",
        "best_config = {}\n",
        "best_config[0] = {'lambda': 0.3, 'lr': 0.00039720306727542226, 'gamma': 0.958235141786408, 'train_batch_size': 960, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-esDtc1RmkQ"
      },
      "outputs": [],
      "source": [
        "#C5\n",
        "best_config = {}\n",
        "best_config[0] = {'lambda': 0.3, 'lr': 0.005623413251903496, 'gamma': 0.9866572109841178, 'train_batch_size': 960, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsx9ipsQlj63"
      },
      "outputs": [],
      "source": [
        "#C7\n",
        "best_config = {}\n",
        "best_config[0] =  {'lambda': 0.1, 'lr': 0.00010000000000000021, 'gamma': 0.9, 'train_batch_size': 960, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qSDk4M0W0gV"
      },
      "outputs": [],
      "source": [
        "#C9\n",
        "best_config = {}\n",
        "best_config[0] =  {'lambda': 0.5, 'lr': 0.00017782794100389265, 'gamma': 0.9610799090397744, 'train_batch_size': 960, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbeRqmBAsI6l"
      },
      "outputs": [],
      "source": [
        "#C11\n",
        "best_config = {}\n",
        "best_config[0] =  {'lambda': 0.3, 'lr': 0.0003484985143235064, 'gamma': 0.9433569781145408, 'train_batch_size': 960, 'env': 'StockTrading_train_env', 'framework': 'tf2', 'eager_tracing': True, 'num_workers': 1, 'num_gpus': 1, 'num_envs_per_worker': 1, 'model': {'use_lstm': True, 'lstm_cell_size': 256, 'lstm_use_prev_action': True, 'lstm_use_prev_reward': True}}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#D2\n",
        "best_config = {}\n",
        "best_config[0] =  {'clip_param': 0.1,\n",
        " 'eager_tracing': False,\n",
        " 'env': 'StockTrading_train_env',\n",
        " 'framework': 'tf2',\n",
        " 'gamma': 0.9037485846525093,\n",
        " 'lambda': 0.9386668141475626,\n",
        " 'lr': 5.000197729565842e-06,\n",
        " 'model': {'lstm_cell_size': 256,\n",
        "  'lstm_use_prev_action': True,\n",
        "  'lstm_use_prev_reward': True,\n",
        "  'use_lstm': True},\n",
        " 'num_envs_per_worker': 1,\n",
        " 'num_gpus': 1,\n",
        " 'num_workers': 1,\n",
        " 'train_batch_size': 2400}\n"
      ],
      "metadata": {
        "id": "V6-umj3nEb6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4RcIBZ5S7mwq"
      },
      "outputs": [],
      "source": [
        "def training(\n",
        "        env_config,\n",
        "        drl_lib,\n",
        "        env,\n",
        "        model_name,\n",
        "        init_ray=True,\n",
        "        **kwargs\n",
        "):\n",
        "   \n",
        "    env_instance = env(config=env_config)\n",
        "\n",
        "    print(env_instance)\n",
        "\n",
        "    rllib_params = kwargs.get(\"rllib_params\")\n",
        "    \n",
        "    agent_rllib = DRLAgent_rllib(\n",
        "            env=env,\n",
        "            price_array=env_config['price_array'],\n",
        "            tech_array=env_config['tech_array'],\n",
        "            turbulence_array=env_config['turbulence_array'],\n",
        "        )\n",
        "    \n",
        "    print(agent_rllib)\n",
        "\n",
        "    model, model_config = agent_rllib.get_model(model_name)\n",
        "\n",
        "    print('got model_config')\n",
        "\n",
        "    model_config[\"lr\"] = best_config[0][\"lr\"]\n",
        "    model_config[\"train_batch_size\"] = rllib_params[\"train_batch_size\"]\n",
        "    model_config[\"gamma\"] = best_config[0][\"gamma\"]\n",
        "    model_config['clip_param'] = best_config[0]['clip_param']\n",
        "\n",
        "    #model_config[\"critic_lr\"] = best_config[0][\"critic_lr\"]\n",
        "    #model_config[\"actor_lr\"] = best_config[0][\"actor_lr\"]\n",
        "    #model_config[\"tau\"] = best_config[0][\"tau\"]\n",
        "\n",
        "    #model_config[\"lambda\"] = best_config[0][\"lambda\"]\n",
        "\n",
        "    #model_config['obs_batch'] = 100\n",
        "\n",
        "    model_config['framework'] = \"tf2\"\n",
        "    model_config['num_workers'] = 4\n",
        "    model_config['num_cpus_per_worker'] = 0 \n",
        "    model_config['num_gpus'] = 1\n",
        "    model_config[\"eager_tracing\"] = True\n",
        "\n",
        "    model_config[\"model\"][\"use_lstm\"] = True\n",
        "    model_config[\"model\"][\"lstm_cell_size\"] = 256\n",
        "    model_config[\"model\"][\"lstm_use_prev_action\"] = True\n",
        "    model_config[\"model\"][\"lstm_use_prev_reward\"] = True\n",
        "\n",
        "    if model_name not in MODELS:\n",
        "            raise NotImplementedError(\"NotImplementedError\")\n",
        "    if init_ray:\n",
        "            ray.init(\n",
        "                ignore_reinit_error=True\n",
        "            )  # Other Ray APIs will not work until `ray.init()` is called.\n",
        "    print('ray initialised')\n",
        "\n",
        "    if model_name == \"ppo\":\n",
        "            trainer = model.PPOTrainer(env=env, logger_creator=custom_logger_creator, config=model_config)\n",
        "    elif model_name == \"a2c\":\n",
        "            trainer = model.A2CTrainer(env=env, config=model_config)\n",
        "    elif model_name == \"ddpg\":\n",
        "            trainer = model.DDPGTrainer(env=env, config=model_config)\n",
        "    elif model_name == \"td3\":\n",
        "            trainer = model.TD3Trainer(env=env, config=model_config)\n",
        "    elif model_name == \"sac\":\n",
        "            trainer = model.SACTrainer(env=env, config=model_config)\n",
        "\n",
        "    print('got trainer')\n",
        "    return(trainer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "HXecMHYV8kJB"
      },
      "outputs": [],
      "source": [
        "def train_model(\n",
        "        total_episodes,\n",
        "        env_config_list,\n",
        "        drl_lib,\n",
        "        env,\n",
        "        model_name,\n",
        "        init_ray=True,\n",
        "        **kwargs\n",
        "):\n",
        "\n",
        "        s = \"{:3d} reward {:6.2f}/{:6.2f}/{:6.2f} len {:6.2f} saved {}\"\n",
        "\n",
        "        trainer = training(\n",
        "                        env_config = env_config_list[0],\n",
        "                        drl_lib='rllib', \n",
        "                        env=env,\n",
        "                        model_name = model_algorithm, \n",
        "                        init_ray=True,\n",
        "                        rllib_params = rllib_params)\n",
        "        #trainer.restore('/tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10')\n",
        "        result = trainer.train()\n",
        "        print(pretty_print(result))\n",
        "            \n",
        "        file_name = trainer.save(\"/tmp/rllib_checkpoint\")\n",
        "\n",
        "        print(s.format(\n",
        "              1,\n",
        "              result[\"episode_reward_min\"],\n",
        "              result[\"episode_reward_mean\"],\n",
        "              result[\"episode_reward_max\"],\n",
        "              result[\"episode_len_mean\"],\n",
        "              file_name\n",
        "            ))\n",
        "\n",
        "        ray.shutdown()\n",
        "\n",
        "        for episode in range(total_episodes-1):\n",
        "            trainer = training(\n",
        "                        env_config = env_config_list[episode+1],\n",
        "                        drl_lib='rllib',\n",
        "                        env=env,\n",
        "                        model_name = model_algorithm, \n",
        "                        init_ray=True,\n",
        "                        rllib_params = rllib_params)\n",
        "                        \n",
        "            trainer.restore(file_name)\n",
        "            result = trainer.train()\n",
        "            print(pretty_print(result))\n",
        "            \n",
        "            file_name = trainer.save(\"/tmp/rllib_checkpoint\")\n",
        "\n",
        "            print(s.format(\n",
        "              episode + 2,\n",
        "              result[\"episode_reward_min\"],\n",
        "              result[\"episode_reward_mean\"],\n",
        "              result[\"episode_reward_max\"],\n",
        "              result[\"episode_len_mean\"],\n",
        "              file_name\n",
        "            ))\n",
        "\n",
        "            ray.shutdown()\n",
        "  \n",
        "        return file_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "VsLR82DV_XVM"
      },
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSH8aaB-8cTK",
        "outputId": "284d504c-f4b2-4e53-dfad-db9112a63e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<ChangedStockTradingEnv instance>\n",
            "<finrl.agents.rllib.models.DRLAgent object at 0x7f1c565719d0>\n",
            "got model_config\n",
            "ray initialised\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=79290)\u001b[0m 2022-06-29 11:36:01,739\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=79289)\u001b[0m 2022-06-29 11:36:02,889\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=79350)\u001b[0m 2022-06-29 11:36:04,069\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=79669)\u001b[0m 2022-06-29 11:36:16,483\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = train_model(\n",
        "      total_episodes = len(train_env_config),\n",
        "      env_config_list = train_env_config,\n",
        "      drl_lib='rllib', \n",
        "      env=env,\n",
        "      model_name = model_algorithm, \n",
        "      rllib_params = rllib_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g37WugV_1pAS"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "z8ddoDHv9btN"
      },
      "outputs": [],
      "source": [
        "def get_config_Test(dic, Number_Days):  \n",
        "\n",
        "    env_config = []\n",
        "\n",
        "    for index in range(Number_Days):\n",
        "\n",
        "      print(index)\n",
        "\n",
        "      price_array, tech_array, turbulence_array = df_to_array(dic[index+Number_Train_Days], False)\n",
        "\n",
        "      config = {\n",
        "          \"price_array\": price_array,\n",
        "          \"tech_array\": tech_array,\n",
        "          \"turbulence_array\": turbulence_array,\n",
        "          \"if_train\": False,\n",
        "      }\n",
        "\n",
        "      env_config.append(config)\n",
        "\n",
        "    return env_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBITmBya70Oy",
        "outputId": "eaccd81c-575b-40dc-e36d-05bea80f03f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Successfully transformed into array\n",
            "1\n",
            "Successfully transformed into array\n",
            "2\n",
            "Successfully transformed into array\n",
            "3\n",
            "Successfully transformed into array\n",
            "4\n",
            "Successfully transformed into array\n",
            "5\n",
            "Successfully transformed into array\n",
            "6\n",
            "Successfully transformed into array\n",
            "7\n",
            "Successfully transformed into array\n",
            "8\n",
            "Successfully transformed into array\n"
          ]
        }
      ],
      "source": [
        "test_env_config = get_config_Test(dic, Number_Test_Days)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DbHTkjrhOy7A"
      },
      "outputs": [],
      "source": [
        "def DRL_prediction(\n",
        "            model_name,\n",
        "            env,\n",
        "            env_instance,\n",
        "            price_array,\n",
        "            tech_array,\n",
        "            turbulence_array,\n",
        "            agent_path,\n",
        "    ):\n",
        "        if model_name not in MODELS:\n",
        "            raise NotImplementedError(\"NotImplementedError\")\n",
        "\n",
        "        if model_name == \"a2c\":\n",
        "            model_config = MODELS[model_name].A2C_DEFAULT_CONFIG.copy()\n",
        "        elif model_name == \"td3\":\n",
        "            model_config = MODELS[model_name].TD3_DEFAULT_CONFIG.copy()\n",
        "        else:\n",
        "            model_config = MODELS[model_name].DEFAULT_CONFIG.copy()\n",
        "        model_config[\"env\"] = env\n",
        "        model_config[\"log_level\"] = \"WARN\"\n",
        "        model_config[\"env_config\"] = {\n",
        "            \"price_array\": price_array,\n",
        "            \"tech_array\": tech_array,\n",
        "            \"turbulence_array\": turbulence_array,\n",
        "            \"if_train\": False}\n",
        "\n",
        "        #model_config[\"lr\"] = best_config[0][\"lr\"]\n",
        "        model_config[\"train_batch_size\"] = rllib_params[\"train_batch_size\"]\n",
        "        #model_config[\"gamma\"] = best_config[0][\"gamma\"]\n",
        "        #model_config['clip_param'] = best_config[0]['clip_param']\n",
        "\n",
        "        #model_config[\"critic_lr\"] = best_config[0][\"critic_lr\"]\n",
        "        #model_config[\"actor_lr\"] = best_config[0][\"actor_lr\"]\n",
        "        #model_config[\"tau\"] = best_config[0][\"tau\"]\n",
        "\n",
        "        #model_config[\"lambda\"] = best_config[0][\"lambda\"]\n",
        "\n",
        "        #model_config[\"output\"] = \"/content/drive/MyDrive/csvfiles\" \n",
        "        #model_config[\"local_dir\"] = \"./trained_models\"\n",
        "        #model_config[\"reuse_actors\"] = True\n",
        "        #model_config[\"callbacks\"] = [TBXLoggerCallback()]\n",
        "\n",
        "        model_config['framework'] = \"tf2\"\n",
        "        model_config['num_workers'] = 4\n",
        "        model_config['num_cpus_per_worker'] = 0 \n",
        "        model_config['num_gpus'] = 1\n",
        "        model_config[\"eager_tracing\"] = True\n",
        "\n",
        "        model_config[\"model\"][\"use_lstm\"] = True\n",
        "        model_config[\"model\"][\"lstm_cell_size\"] = 256\n",
        "        model_config[\"model\"][\"lstm_use_prev_action\"] = True\n",
        "        model_config[\"model\"][\"lstm_use_prev_reward\"] = True\n",
        "\n",
        "        env_config = {\n",
        "            \"price_array\": price_array,\n",
        "            \"tech_array\": tech_array,\n",
        "            \"turbulence_array\": turbulence_array,\n",
        "            \"if_train\": False,\n",
        "        }\n",
        "        env_instance = env(config=env_config)\n",
        "\n",
        "        # ray.init() # Other Ray APIs will not work until `ray.init()` is called.\n",
        "        if model_name == \"ppo\":\n",
        "            trainer = MODELS[model_name].PPOTrainer(env=env, config=model_config)\n",
        "        elif model_name == \"a2c\":\n",
        "            trainer = MODELS[model_name].A2CTrainer(env=env, config=model_config)\n",
        "        elif model_name == \"ddpg\":\n",
        "            trainer = MODELS[model_name].DDPGTrainer(env=env, config=model_config)\n",
        "        elif model_name == \"td3\":\n",
        "            trainer = MODELS[model_name].TD3Trainer(env=env, config=model_config)\n",
        "        elif model_name == \"sac\":\n",
        "            trainer = MODELS[model_name].SACTrainer(env=env, config=model_config)\n",
        "\n",
        "        print('got trainer')\n",
        "        \n",
        "        #try:\n",
        "         #   trainer.restore(agent_path)\n",
        "          #  print(\"Restoring from checkpoint path\", agent_path)\n",
        "        #except BaseException:\n",
        "         #   raise ValueError(\"Fail to load agent!\")\n",
        "        \n",
        "        trainer.restore(agent_path)\n",
        "        print(\"restored agent\")\n",
        "        print(\"Restoring from checkpoint path\", agent_path)\n",
        "\n",
        "        # test on the testing env\n",
        "        episode_returns = []  # the cumulative_return / initial_account\n",
        "        episode_total_assets = [env_instance.initial_total_asset]\n",
        "        obs = env_instance.reset()\n",
        "        state = [np.zeros([256], np.float32) for _ in range(2)]\n",
        "        prev_a = [0, 0]\n",
        "        prev_r = 0.0\n",
        "        done = False\n",
        "        total_reward = 0.0\n",
        "\n",
        "        print(\"starting the loop\")\n",
        "\n",
        "        while not done:\n",
        "            action, state, _ = trainer.compute_single_action(obs, state, prev_action=prev_a, prev_reward=prev_r)\n",
        "            obs, reward, done, _ = env_instance.step(action)\n",
        "            \n",
        "\n",
        "            prev_a = action\n",
        "            prev_r = reward\n",
        "\n",
        "            total_reward += reward\n",
        "\n",
        "            total_asset = (\n",
        "                    env_instance.amount\n",
        "                    + (env_instance.price_ary[env_instance.day] * env_instance.stocks).sum()\n",
        "            )\n",
        "            episode_total_assets.append(total_asset)\n",
        "            episode_return = total_asset / env_instance.initial_total_asset\n",
        "            episode_returns.append(episode_return)\n",
        "        ray.shutdown()\n",
        "        print(\"episode return: \" + str(episode_return))\n",
        "        print(\"Test Finished!\")\n",
        "        return episode_total_assets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JO0zxs2a7yYm"
      },
      "outputs": [],
      "source": [
        "def DRL_prediction(\n",
        "            model_name,\n",
        "            env,\n",
        "            env_instance,\n",
        "            price_array,\n",
        "            tech_array,\n",
        "            turbulence_array,\n",
        "            agent_path,\n",
        "    ):\n",
        "        if model_name not in MODELS:\n",
        "            raise NotImplementedError(\"NotImplementedError\")\n",
        "\n",
        "        if model_name == \"a2c\":\n",
        "            model_config = MODELS[model_name].A2C_DEFAULT_CONFIG.copy()\n",
        "        elif model_name == \"td3\":\n",
        "            model_config = MODELS[model_name].TD3_DEFAULT_CONFIG.copy()\n",
        "        else:\n",
        "            model_config = MODELS[model_name].DEFAULT_CONFIG.copy()\n",
        "        model_config[\"env\"] = env\n",
        "        model_config[\"log_level\"] = \"WARN\"\n",
        "        model_config[\"env_config\"] = {\n",
        "            \"price_array\": price_array,\n",
        "            \"tech_array\": tech_array,\n",
        "            \"turbulence_array\": turbulence_array,\n",
        "            \"if_train\": False,\n",
        "        }\n",
        "\n",
        "        #model_config[\"model\"][\"use_lstm\"] = True\n",
        "        #model_config[\"model\"][\"lstm_cell_size\"] = 256\n",
        "        #model_config[\"model\"][\"lstm_use_prev_action\"] = True\n",
        "        #model_config[\"model\"][\"lstm_use_prev_reward\"] = True\n",
        "\n",
        "        env_config = {\n",
        "            \"price_array\": price_array,\n",
        "            \"tech_array\": tech_array,\n",
        "            \"turbulence_array\": turbulence_array,\n",
        "            \"if_train\": False,\n",
        "        }\n",
        "        #env_instance = env(config=env_config)\n",
        "\n",
        "        # ray.init() # Other Ray APIs will not work until `ray.init()` is called.\n",
        "        if model_name == \"ppo\":\n",
        "            trainer = MODELS[model_name].PPOTrainer(env=env, config=model_config)\n",
        "        elif model_name == \"a2c\":\n",
        "            trainer = MODELS[model_name].A2CTrainer(env=env, config=model_config)\n",
        "        elif model_name == \"ddpg\":\n",
        "            trainer = MODELS[model_name].DDPGTrainer(env=env, config=model_config)\n",
        "        elif model_name == \"td3\":\n",
        "            trainer = MODELS[model_name].TD3Trainer(env=env, config=model_config)\n",
        "        elif model_name == \"sac\":\n",
        "            trainer = MODELS[model_name].SACTrainer(env=env, config=model_config)\n",
        "\n",
        "        print('got trainer')\n",
        "        \n",
        "        #try:\n",
        "         #   trainer.restore(agent_path)\n",
        "          #  print(\"Restoring from checkpoint path\", agent_path)\n",
        "        #except BaseException:\n",
        "         #   raise ValueError(\"Fail to load agent!\")\n",
        "        \n",
        "        trainer.restore(agent_path)\n",
        "        print(\"restored agent\")\n",
        "        print(\"Restoring from checkpoint path\", agent_path)\n",
        "\n",
        "        state = env_instance.reset()\n",
        "        episode_returns = []  # the cumulative_return / initial_account\n",
        "        episode_total_assets = [env_instance.initial_total_asset]\n",
        "        actions_list = []\n",
        "        done = False\n",
        "        while not done:\n",
        "            action = trainer.compute_single_action(state)\n",
        "            action_list.append(action)\n",
        "            state, reward, done, _ = env_instance.step(action)\n",
        "\n",
        "            total_asset = (\n",
        "                    env_instance.amount\n",
        "                    + (env_instance.price_ary[env_instance.day] * env_instance.stocks).sum()\n",
        "            )\n",
        "            episode_total_assets.append(total_asset)\n",
        "            episode_return = total_asset / env_instance.initial_total_asset\n",
        "            episode_returns.append(episode_return)\n",
        "        ray.shutdown()\n",
        "        print(\"episode return: \" + str(episode_return))\n",
        "        print(\"Test Finished!\")\n",
        "        return episode_total_assets, action_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-HhJZqEj7D6V"
      },
      "outputs": [],
      "source": [
        "def test(\n",
        "        env_config,\n",
        "        env,\n",
        "        capital,\n",
        "        model_name,\n",
        "        cwd,\n",
        "        if_vix=True,\n",
        "        **kwargs\n",
        "):\n",
        "\n",
        "    env_instance = env(config=env_config, initial_capital=capital)\n",
        "\n",
        "    # load elegantrl needs state dim, action dim and net dim\n",
        "    net_dimension = kwargs.get(\"net_dimension\", 2 ** 7)\n",
        "    #cwd = \"./trained_\" + str(model_name)\n",
        "\n",
        "    print(\"price_array: \", len(env_config[\"price_array\"]))\n",
        "\n",
        "        # load agent\n",
        "    \n",
        "    #episode_capital = [capital]\n",
        "    episode_total_assets = DRL_prediction(\n",
        "            model_name=model_name,\n",
        "            env=env,\n",
        "            env_instance = env_instance,\n",
        "            price_array=env_config[\"price_array\"],\n",
        "            tech_array=env_config[\"tech_array\"],\n",
        "            turbulence_array=env_config[\"turbulence_array\"],\n",
        "            agent_path=cwd,\n",
        "        )\n",
        "    account_value = episode_total_assets\n",
        "\n",
        "    return account_value\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "GZlOoiqkMdIT"
      },
      "outputs": [],
      "source": [
        "ray.shutdown()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxYoWCDa02TW",
        "outputId": "79b0661d-0f96-4cdc-91fa-f6b35d8437da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "price_array:  481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=21960)\u001b[0m 2022-06-29 11:02:50,947\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=21959)\u001b[0m 2022-06-29 11:02:51,036\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=22029)\u001b[0m 2022-06-29 11:02:53,104\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=22041)\u001b[0m 2022-06-29 11:02:53,207\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n",
            "restored agent\n",
            "Restoring from checkpoint path /tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10\n",
            "starting the loop\n",
            "episode return: 0.8700540360000091\n",
            "Test Finished!\n",
            "1\n",
            "price_array:  481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=23773)\u001b[0m 2022-06-29 11:04:17,565\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=23772)\u001b[0m 2022-06-29 11:04:17,818\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=23820)\u001b[0m 2022-06-29 11:04:19,807\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=23851)\u001b[0m 2022-06-29 11:04:20,474\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n",
            "restored agent\n",
            "Restoring from checkpoint path /tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10\n",
            "starting the loop\n",
            "episode return: 0.9007593810000079\n",
            "Test Finished!\n",
            "2\n",
            "price_array:  481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=25759)\u001b[0m 2022-06-29 11:05:40,874\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=25760)\u001b[0m 2022-06-29 11:05:40,981\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=25856)\u001b[0m 2022-06-29 11:05:43,831\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=25898)\u001b[0m 2022-06-29 11:05:45,910\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n",
            "restored agent\n",
            "Restoring from checkpoint path /tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10\n",
            "starting the loop\n",
            "episode return: 0.8168705940000085\n",
            "Test Finished!\n",
            "3\n",
            "price_array:  481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=28647)\u001b[0m 2022-06-29 11:08:02,334\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=28646)\u001b[0m 2022-06-29 11:08:02,510\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=28700)\u001b[0m 2022-06-29 11:08:04,384\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=28711)\u001b[0m 2022-06-29 11:08:04,653\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n",
            "restored agent\n",
            "Restoring from checkpoint path /tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10\n",
            "starting the loop\n",
            "episode return: 0.8616025040000082\n",
            "Test Finished!\n",
            "4\n",
            "price_array:  481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=31647)\u001b[0m 2022-06-29 11:10:22,963\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=31648)\u001b[0m 2022-06-29 11:10:22,997\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=31713)\u001b[0m 2022-06-29 11:10:25,317\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=31691)\u001b[0m 2022-06-29 11:10:25,833\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n",
            "restored agent\n",
            "Restoring from checkpoint path /tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10\n",
            "starting the loop\n",
            "episode return: 0.8696510630000073\n",
            "Test Finished!\n",
            "5\n",
            "price_array:  481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=36053)\u001b[0m 2022-06-29 11:13:43,529\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=36057)\u001b[0m 2022-06-29 11:13:43,914\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=36138)\u001b[0m 2022-06-29 11:13:46,193\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=36354)\u001b[0m 2022-06-29 11:13:57,664\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n",
            "restored agent\n",
            "Restoring from checkpoint path /tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10\n",
            "starting the loop\n",
            "episode return: 0.8678335150000065\n",
            "Test Finished!\n",
            "6\n",
            "price_array:  481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=40403)\u001b[0m 2022-06-29 11:17:04,373\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=40404)\u001b[0m 2022-06-29 11:17:04,490\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=40451)\u001b[0m 2022-06-29 11:17:07,187\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=40725)\u001b[0m 2022-06-29 11:17:16,347\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n",
            "restored agent\n",
            "Restoring from checkpoint path /tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10\n",
            "starting the loop\n",
            "episode return: 0.8198178700000098\n",
            "Test Finished!\n",
            "7\n",
            "price_array:  481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=46881)\u001b[0m 2022-06-29 11:21:57,240\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=47010)\u001b[0m 2022-06-29 11:22:05,538\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=47277)\u001b[0m 2022-06-29 11:22:16,418\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=47490)\u001b[0m 2022-06-29 11:22:24,785\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n",
            "restored agent\n",
            "Restoring from checkpoint path /tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10\n",
            "starting the loop\n",
            "episode return: 0.8609543120000077\n",
            "Test Finished!\n",
            "8\n",
            "price_array:  481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(RolloutWorker pid=53989)\u001b[0m 2022-06-29 11:27:04,505\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=53988)\u001b[0m 2022-06-29 11:27:04,881\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=54210)\u001b[0m 2022-06-29 11:27:13,834\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n",
            "\u001b[2m\u001b[36m(RolloutWorker pid=54518)\u001b[0m 2022-06-29 11:27:24,036\tWARNING env.py:136 -- Your env doesn't have a .spec.max_episode_steps attribute. This is fine if you have set 'horizon' in your config dictionary, or `soft_horizon`. However, if you haven't, 'horizon' will default to infinity, and your environment will not be reset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "got trainer\n",
            "restored agent\n",
            "Restoring from checkpoint path /tmp/rllib_checkpoint/checkpoint_000010/checkpoint-10\n",
            "starting the loop\n",
            "episode return: 0.8395146390000087\n",
            "Test Finished!\n",
            "[10000000.0, 870054.036000009, 900759.3810000079, 816870.5940000085, 861602.5040000081, 869651.0630000073, 867833.5150000065, 819817.8700000098, 860954.3120000077, 839514.6390000087]\n"
          ]
        }
      ],
      "source": [
        "test_results = []\n",
        "starting_capital = 10e6\n",
        "final_capital = [starting_capital]\n",
        "\n",
        "for index in range(len(test_env_config)):\n",
        "\n",
        "      print(index)\n",
        "\n",
        "      account_value = test(env_config = test_env_config[index],\n",
        "                      env=env, \n",
        "                      capital = final_capital[index], \n",
        "                      model_name=model_algorithm,\n",
        "                      cwd =  checkpoint_path,\n",
        "                      net_dimension = 512)\n",
        "      final_capital.append(account_value[-1])\n",
        "      ray.shutdown()\n",
        "      test_results.append(account_value)\n",
        "print(final_capital)\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "hyEqvQj17tgF",
        "outputId": "23a261e7-cfcc-43ca-9bb9-fb065a9ffd15"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_53a638d0-dd2d-4624-acf3-9da21b03d896\", \"D1 test 1.csv\", 10389)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_66977bb9-9763-43d5-a53a-1793283448b9\", \"D1 test 2.csv\", 10389)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ef6a14db-d26e-4cf8-9bb7-6c53fa9d971c\", \"D1 test 3.csv\", 10426)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7d5716ba-3a0f-443d-b178-0d0f2b0b7532\", \"D1 test 4.csv\", 10342)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_346ba0ba-6c26-4081-8125-caa4fba18a0e\", \"D1 test 5.csv\", 10325)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a91217fa-ed29-4025-9aca-84d2a9a847ad\", \"D1 test 6.csv\", 10379)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_829c48df-b008-4e0d-b8f2-bf2d8a0b8cfc\", \"D1 test 7.csv\", 10393)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dfee696e-6f99-45f4-83d4-20f2503255e4\", \"D1 test 8.csv\", 10372)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_99530a21-3166-4578-8173-5400aa3b60f8\", \"D1 test 9.csv\", 10334)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "for index in range(len(test_results)):\n",
        "\n",
        "  df_account_test = pd.DataFrame(data=test_results[index],columns=['account_value'])\n",
        "  file_name = \"D1 test \"+str(index+1)+\".csv\"\n",
        "  df_account_test.to_csv(file_name)\n",
        "  files.download(file_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Optimisation_DayTrading_FinRL_JSE_Singe_Stock.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}